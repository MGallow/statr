# Generated by using Rcpp::compileAttributes() -> do not
# edit by hand Generator token:
# 10BE3573-1514-4C36-9D1C-5A225CD40393

#' @title Logitc (c++)
#' @description Computes the logit for u
#' @param u some number
#' @return returns the logit of u
#' @examples
#' logit(X*beta)
#'
logitc <- function(u) {
    .Call("statr_logitc", PACKAGE = "statr", u)
}

#' @title Gradient of Logistic Regression (IRLS) (c++)
#' @description Computes the gradient of logistic regression (optional ridge regularization term). We use this to determine if the KKT conditions are satisfied. This function is to be used with the 'IRLS' function.
#'
#' @param betas beta estimates (includes intercept)
#' @param X matrix or data frame
#' @param y response vector of 0,1
#' @param lam tuning parameter for ridge regularization term
#' @param vec vector to specify which coefficients will be penalized
#' @return returns the gradient
#' @examples
#' gradient_IRLS_logistic(betas, X, y, lam = 0.1, penalty = 'ridge')
#'
gradient_IRLS_logisticc <- function(betas, X, y, lam = 0, 
    vec = 0L) {
    .Call("statr_gradient_IRLS_logisticc", PACKAGE = "statr", 
        betas, X, y, lam, vec)
}

#' @title Iterative Re-Weighted Least Squares (c++)
#' @description Computes the logistic regression coefficient estimates using the iterative re-weighted least squares (IRLS) algorithm. This function is to be used with the 'logisticr' function.
#'
#' @param betas beta estimates (includes intercept)
#' @param X matrix or data frame
#' @param y matrix or vector of response 0,1
#' @param lam tuning parameter for regularization term
#' @param vec optional vector to specify which coefficients will be penalized
#' @param intercept Defaults to TRUE
#' @param tol tolerance - used to determine algorithm convergence
#' @param maxit maximum iterations
#' @return returns beta estimates (includes intercept), total iterations, and gradients.
#' @examples
#' IRLSc(X, y, n.list = c(rep(1, n)), lam = 0.1, alpha = 1.5)
#'
IRLSc <- function(X, y, lam = 0, intercept = TRUE, tol = 1e-05, 
    maxit = 1e+05, vec = 0L) {
    .Call("statr_IRLSc", PACKAGE = "statr", X, y, lam, intercept, 
        tol, maxit, vec)
}

#' @title Gradient of Logistic Regression (MM) (c++)
#' @description Computes the gradient of logistic regression (optional ridge regularization term). We use this to determine if the KKT conditions are satisfied. This function is to be used with the 'MM' function.
#'
#' @param betas beta estimates (includes intercept)
#' @param X matrix or data frame
#' @param y response vector of 0,1
#' @param lam tuning parameter for ridge regularization term
#' @param alpha optional tuning parameter for bridge regularization term. Defaults to 'alpha = 1.5'
#' @param gamma indicator function. 'gamma = 1' for ridge, 'gamma = 0' for bridge. Defaults to 'gamma = 1'
#' @param vec vector to specify which coefficients will be penalized
#' @return returns the gradient
#' @examples
#' gradient_MM_logistic(betas, X, y, lam = 0.1, alpha = 1.5, penalty = 'bridge')
#'
gradient_MM_logisticc <- function(betas, X, y, lam = 0, alpha = 1.5, 
    gamma = 1, vec = 0L) {
    .Call("statr_gradient_MM_logisticc", PACKAGE = "statr", 
        betas, X, y, lam, alpha, gamma, vec)
}

#' @title Majorize-Minimization function (c++)
#' @description This function utilizes the MM algorithm. It will be used to compute the logistic regression coefficient estimates. This function is to be used with the 'logisticr' function.
#'
#' @param X matrix or data frame
#' @param y matrix or vector of response 0,1
#' @param lam optional tuning parameter for ridge regularization term. Defaults to 'lam = 0'
#' @param alpha optional tuning parameter for bridge regularization term. Defaults to 'alpha = 1.5'
#' @param vec optional vector to specify which coefficients will be penalized
#' @param gamma gamma indicator function. 'gamma = 1' for ridge, 'gamma = 0' for bridge. Defaults to 'gamma = 1'
#' @param intercept defaults to TRUE
#' @param tol tolerance - used to determine algorithm convergence
#' @param maxit maximum iterations
#' @return returns beta estimates (includes intercept), total iterations, and gradients.
#' @examples
#' MMc(X, y)
#'
MMc <- function(X, y, lam = 0, alpha = 1.5, gamma = 1, intercept = TRUE, 
    tol = 1e-05, maxit = 1e+05, vec = 0L) {
    .Call("statr_MMc", PACKAGE = "statr", X, y, lam, alpha, 
        gamma, intercept, tol, maxit, vec)
}

#' @title Linearc (c++)
#' @description Computes the linear regression coefficient estimates (ridge-penalization and weights, optional)
#' @param X matrix
#' @param y matrix
#' @param lam optional tuning parameter for ridge regularization term. Defaults to 'lam = 0'
#' @param weights optional vector of weights for weighted least squares
#' @param intercept add column of ones if not already present. Defaults to TRUE
#' @param kernel use linear kernel to compute ridge regression coefficeients. Defaults to true when p >> n
#' @return returns the coefficient estimates
#' @export
#' @examples
#' Weighted ridge regression
#' library(dplyr)
#' X = dplyr::select(iris, -c(Species, Sepal.Length))
#' y = dplyr::select(iris, Sepal.Length)
#' linearc(X, y, lam = 0.1, weights = rep(1:150))
#'
#' Kernelized ridge regression
#' linearc(X, y, lam = 0.1, kernel = T)
#'
linearc <- function(X, y, lam = 0, weights = 0L, intercept = TRUE, 
    kernel = FALSE) {
    .Call("statr_linearc", PACKAGE = "statr", X, y, lam, 
        weights, intercept, kernel)
}

