# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' @title K fold (c++)
#' @description creates vector of shuffled indices
#'
#' @param n number of eleemtns
#' @param K number of folds
#' @return returns vector
#' @examples
#' kfold(10, 3)
#'
kfold <- function(n, K) {
    .Call('statr_kfold', PACKAGE = 'statr', n, K)
}

#' @title CV Logisticc (c++)
#' @description Computes the coefficient estimates for logistic regression. ridge regularization and bridge regularization optional.
#'
#' @param X matrix or data frame
#' @param y matrix or vector of response values 0,1
#' @param lam vector of tuning parameters for ridge regularization term. Defaults to `lam = 0`
#' @param alpha vector of tuning parameters for bridge regularization term. Defaults to 'alpha = 1.5'
#' @param penalty choose from c('none', 'ridge', 'bridge'). Defaults to 'none'
#' @param vec optional vector to specify which coefficients will be penalized
#' @param intercept Defaults to TRUE
#' @param method optimization algorithm. Choose from 'IRLS' or 'MM'. Defaults to 'IRLS'
#' @param tol tolerance - used to determine algorithm convergence. Defaults to 1e-5
#' @param maxit maximum iterations. Defaults to 1e5
#' @param init initialization of betas
#' @param K specify number of folds in cross validation, if necessary
#'
#' @return returns best lambda, best alpha, cv.errors
#' @export
#' @examples
#' CV Logistic Regression
#'
CV_logisticc <- function(X, y, lam = 0L, alpha = 0L, penalty = "none", intercept = TRUE, method = "IRLS", tol = 1e-5, maxit = 1e4, vec = 0L, K = 3L) {
    .Call('statr_CV_logisticc', PACKAGE = 'statr', X, y, lam, alpha, penalty, intercept, method, tol, maxit, vec, K)
}

#' @title Logitc (c++)
#' @description Computes the logit for u
#' @param u some number
#' @return returns the logit of u
#' @examples
#' logit(X*beta)
#'
logitc <- function(u) {
    .Call('statr_logitc', PACKAGE = 'statr', u)
}

#' @title Gradient of Logistic Regression (IRLS) (c++)
#' @description Computes the gradient of logistic regression (optional ridge regularization term). We use this to determine if the KKT conditions are satisfied. This function is to be used with the 'IRLS' function.
#'
#' @param betas estimates (includes intercept)
#' @param X matrix or data frame
#' @param y response vector of 0,1
#' @param lam tuning parameter for ridge regularization term
#' @param vec vector to specify which coefficients will be penalized
#' @return returns the gradient
#' @examples
#' gradient_IRLS_logistic(betas, X, y, lam = 0.1, penalty = 'ridge')
#'
gradient_IRLS_logisticc <- function(betas, X, y, lam = 0, vec = 0L) {
    .Call('statr_gradient_IRLS_logisticc', PACKAGE = 'statr', betas, X, y, lam, vec)
}

#' @title Iterative Re-Weighted Least Squares (c++)
#' @description Computes the logistic regression coefficient estimates using the iterative re-weighted least squares (IRLS) algorithm. This function is to be used with the 'logisticr' function.
#'
#' @param betas beta estimates (includes intercept)
#' @param X matrix or data frame
#' @param y matrix or vector of response 0,1
#' @param lam tuning parameter for regularization term
#' @param vec optional vector to specify which coefficients will be penalized
#' @param intercept Defaults to TRUE
#' @param tol tolerance - used to determine algorithm convergence
#' @param maxit maximum iterations
#' @return returns beta estimates (includes intercept), total iterations, and gradients.
#' @examples
#' IRLSc(X, y, n.list = c(rep(1, n)), lam = 0.1, alpha = 1.5)
#'
IRLSc <- function(X, y, lam = 0, intercept = TRUE, tol = 1e-5, maxit = 1e5, vec = 0L) {
    .Call('statr_IRLSc', PACKAGE = 'statr', X, y, lam, intercept, tol, maxit, vec)
}

#' @title Gradient of Linear Regression (c++)
#' @description Computes the gradient of linear regression (optional ridge regularization term). This function is to be used with the 'Linearr' function.
#'
#' @param beta estimates (includes intercept)
#' @param X matrix or data frame
#' @param y response vector of 0,1
#' @param lam tuning parameter for ridge regularization term
#' @param weights option vector of weights for weighted least squares
#' @param vec vector to specify which coefficients will be penalized
#' @return returns the gradient
#' @examples
#' gradient_linearc(betas, X, y, lam = 0.1)
#'
gradient_linearc <- function(betas, X, y, lam = 0, weights = 0L, intercept = TRUE) {
    .Call('statr_gradient_linearc', PACKAGE = 'statr', betas, X, y, lam, weights, intercept)
}

#' @title Linearc (c++)
#' @description Computes the linear regression coefficient estimates (ridge-penalization and weights, optional)
#' @param X matrix
#' @param y matrix
#' @param lam optional tuning parameter for ridge regularization term. Defaults to 'lam = 0'
#' @param weights optional vector of weights for weighted least squares
#' @param intercept add column of ones if not already present. Defaults to TRUE
#' @param kernel use linear kernel to compute ridge regression coefficeients. Defaults to true when p >> n
#' @return returns the coefficient estimates
#' @export
#' @examples
#' Weighted ridge regression
#' library(dplyr)
#' X = dplyr::select(iris, -c(Species, Sepal.Length))
#' y = dplyr::select(iris, Sepal.Length)
#' linearc(X, y, lam = 0.1, weights = rep(1:150))
#'
#' Kernelized ridge regression
#' linearc(X, y, lam = 0.1, kernel = T)
#'
linearc <- function(X, y, lam = 0, weights = 0L, intercept = TRUE, kernel = FALSE) {
    .Call('statr_linearc', PACKAGE = 'statr', X, y, lam, weights, intercept, kernel)
}

#' @title Logistic Regression (c++)
#' @description Computes the coefficient estimates for logistic regression. ridge regularization and bridge regularization optional.
#'
#' @param X matrix or data frame
#' @param y matrix or vector of response values 0,1
#' @param lam optional tuning parameter for ridge regularization term. Defaults to `lam = 0`
#' @param alpha optional tuning parameter for bridge regularization term. Defaults to 'alpha = 1.5'
#' @param penalty choose from c('none', 'ridge', 'bridge'). Defaults to 'none'
#' @param vec optional vector to specify which coefficients will be penalized
#' @param intercept Defaults to TRUE
#' @param method optimization algorithm. Choose from 'IRLS' or 'MM'. Defaults to 'IRLS'
#' @param tol tolerance - used to determine algorithm convergence. Defaults to 1e-5
#' @param maxit maximum iterations. Defaults to 1e5
#' @return returns beta estimates (includes intercept), total iterations, and gradients.
#' @export
#' @examples
#' Logistic Regression
#' library(dplyr)
#' X = as.matrix(dplyr::select(iris, -Species))
#' y = as.matrix(dplyr::select(iris, Species))
#' y$Species = ifelse(y$Species == 'setosa', 1, 0)
#' logisticr(X, y)
#'
#' ridge Logistic Regression with IRLS
#' logisticc(X, y, lam = 0.1, penalty = 'ridge')
#'
#' ridge Logistic Regression with MM
#' logisticc(X, y, lam = 0.1, penalty = 'ridge', method = 'MM')
#'
#' bridge Logistic Regression
#' (Defaults to MM -- IRLS will return error)
#' logisticc(X, y, lam = 0.1, alpha = 1.5, penalty = 'bridge')
#'
logisticc <- function(X, y, lam = 0, alpha = 1.5, penalty = "none", intercept = TRUE, method = "IRLS", tol = 1e-5, maxit = 1e5, vec = 0L) {
    .Call('statr_logisticc', PACKAGE = 'statr', X, y, lam, alpha, penalty, intercept, method, tol, maxit, vec)
}

#' @title Gradient of Logistic Regression (MM) (c++)
#' @description Computes the gradient of logistic regression (optional ridge regularization term). We use this to determine if the KKT conditions are satisfied. This function is to be used with the 'MM' function.
#'
#' @param betas beta estimates (includes intercept)
#' @param X matrix or data frame
#' @param y response vector of 0,1
#' @param lam tuning parameter for ridge regularization term
#' @param alpha optional tuning parameter for bridge regularization term. Defaults to 'alpha = 1.5'
#' @param gamma indicator function. 'gamma = 1' for ridge, 'gamma = 0' for bridge. Defaults to 'gamma = 1'
#' @param vec vector to specify which coefficients will be penalized
#' @return returns the gradient
#' @examples
#' gradient_MM_logistic(betas, X, y, lam = 0.1, alpha = 1.5, penalty = 'bridge')
#'
gradient_MM_logisticc <- function(betas, X, y, lam = 0, alpha = 1.5, gamma = 1, vec = 0L) {
    .Call('statr_gradient_MM_logisticc', PACKAGE = 'statr', betas, X, y, lam, alpha, gamma, vec)
}

#' @title Majorize-Minimization function (c++)
#' @description This function utilizes the MM algorithm. It will be used to compute the logistic regression coefficient estimates. This function is to be used with the 'logisticr' function.
#'
#' @param X matrix or data frame
#' @param y matrix or vector of response 0,1
#' @param lam optional tuning parameter for ridge regularization term. Defaults to 'lam = 0'
#' @param alpha optional tuning parameter for bridge regularization term. Defaults to 'alpha = 1.5'
#' @param vec optional vector to specify which coefficients will be penalized
#' @param gamma gamma indicator function. 'gamma = 1' for ridge, 'gamma = 0' for bridge. Defaults to 'gamma = 1'
#' @param intercept defaults to TRUE
#' @param tol tolerance - used to determine algorithm convergence
#' @param maxit maximum iterations
#' @return returns beta estimates (includes intercept), total iterations, and gradients.
#' @examples
#' MMc(X, y)
#'
MMc <- function(X, y, lam = 0, alpha = 1.5, gamma = 1, intercept = TRUE, tol = 1e-5, maxit = 1e5, vec = 0L) {
    .Call('statr_MMc', PACKAGE = 'statr', X, y, lam, alpha, gamma, intercept, tol, maxit, vec)
}

