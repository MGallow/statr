---
title: "statr"
author: "Matt Galloway"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Installation

The easiest way to install is from the development version from Github:

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("MGallow/statr")
```

If there are any issues/bugs, please let me know: [github](https://github.com/MGallow/statr/issues). You can also contact me via my [website](http://users.stat.umn.edu/~gall0441/).

# Overview

`statr` is a personal R package that I have created for organizational/convenience purposes. A (possibly incomplete) list of functions contained in the package can be found below:

* `tidy()` tidy's R package code and updates documentation
* `timeit()` prints the computation time of a function
* `bsearch()` is a bi-section search algorithm for minimizing a univariate function
* `dsearch()` is a dichotomous search algorithm for minimizing a univariate function
* `linearr()` computes the linear regression coefficient estimates (ridge regularization and weights optional)
* `predict_linearr()` generates predictions and loss metric for linear regression
* `logisticr()` computes the coefficient estimates for logistic regression (ridge and bridge regularization optional)
* `predict_logisticr()` generates predictions and loss metrics for logistic regression

# Functions

## timeit

As a simple example, we will time the `lm()` function with the `cars` data set:

```{r message = FALSE}
library(statr)

#time lm()
timeit(lm(dist ~ speed, data = cars))

```

## bsearch

## dsearch

## linearr

For the next few examples we will use the `iris` data set:

```{r message = FALSE}

#iris data set
X = dplyr::select(iris, -c(Species, Sepal.Length))
y = dplyr::select(iris, Sepal.Length)

```

Note that the `Sepal.Length` is the response. All other variables will be used as predictors except `Species`.

Let's perform a simple linear regression:

```{r message = FALSE}

#linear regression
linearr(X, y)

```

Next, we will try ridge regression. At the moment the only regularization penalty available in the `linearr` function is the ridge penalty -- therefore we only need to specify our tuning parameter `lam`:

```{r message = FALSE}

#ridge regression (set lam = 0.1)
linearr(X, y, lam = 0.1)

```

## predict_linearr

## logisticr

logistic regression:

ridge logistic regression using IRLS algorithm:

ridge logistic regression using MM algorithm:

bridge logistic regression (requires MM algorithm):

## predict_logisticr


```{r, message = FALSE}
library(statr)

#we will use the iris data set
X = dplyr::select(iris, -c(Species, Sepal.Length))
y = dplyr::select(iris, Sepal.Length)
y_class = ifelse(dplyr::select(iris, Species) == "setosa", 1, 0)

#ridge regression
linearr(X, y, lam = 0.1)

#ridge logistic regression (IRLS)
logisticr(X, y_class, lam = 0.1, penalty = "ridge")

#ridge logistic regression (MM)
logisticr(X, y_class, lam = 0.1, penalty = "ridge", method = "MM")

#bridge logistic regression (MM)
fit = logisticr(X, y_class, lam = 0.1, alpha = 1.2, penalty = "bridge")
fit

#predict using bridge logistic regression estimates
predict_logisticr(fit, X[1:3,], y_class[1:3])
```
