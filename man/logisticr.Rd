% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/logistic.R
\name{logisticr}
\alias{logisticr}
\title{Logistic Regression}
\usage{
logisticr(X, y, lam = seq(0, 2, 0.1), alpha = 1.5, penalty = "none",
  intercept = TRUE, method = "IRLS", tol = 1e-05, maxit = 1e+05,
  vec = NULL, init = 1, criteria = "logloss", K = 5)
}
\arguments{
\item{X}{matrix or data frame}

\item{y}{matrix or vector of response values 0,1}

\item{lam}{optional tuning parameter(s) for ridge regularization term. If passing a list of values, the function will choose optimal value based on K-fold cross validation. Defaults to `lam = seq(0, 2, 0.1)`}

\item{alpha}{optional tuning parameter for bridge regularization term. If passing a list of values, the function will choose the optimal value based on K-fold cross validation. Defaults to 'alpha = 1.5'}

\item{penalty}{choose from c('none', 'ridge', 'bridge'). Defaults to 'none'}

\item{intercept}{Defaults to TRUE}

\item{method}{optimization algorithm. Choose from 'IRLS' or 'MM'. Defaults to 'IRLS'}

\item{tol}{tolerance - used to determine algorithm convergence. Defaults to 10^-5}

\item{maxit}{maximum iterations. Defaults to 10^5}

\item{vec}{optional vector to specify which coefficients will be penalized}

\item{init}{optional initialization for MM algorithm}

\item{criteria}{specify the criteria for cross validation. Choose from c('mse', 'logloss', 'misclass'). Defauls to 'logloss'}

\item{K}{specify number of folds for cross validation, if necessary}
}
\value{
returns selected tuning parameters, beta estimates (includes intercept), MSE, log loss, misclassification rate, total iterations, and gradients.
}
\description{
Computes the coefficient estimates for logistic regression. ridge regularization and bridge regularization optional.
}
\examples{
Logistic Regression
library(dplyr)
X = dplyr::select(iris, -Species)
y = dplyr::select(iris, Species)
y$Species = ifelse(y$Species == 'setosa', 1, 0)
logisticr(X, y)

ridge Logistic Regression with IRLS
logistir(X, y, lam = 0.1, penalty = 'ridge')

ridge Logistic Regression with MM
logisticr(X, y, lam = 0.1, penalty = 'ridge', method = 'MM')

bridge Logistic Regression
(Defaults to MM -- IRLS will return error)
logisticr(X, y, lam = 0.1, alpha = 1.5, penalty = 'bridge')
}
